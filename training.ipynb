{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5573c7c4",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-08T07:18:03.196853Z",
     "iopub.status.busy": "2026-01-08T07:18:03.196560Z",
     "iopub.status.idle": "2026-01-08T07:18:22.455893Z",
     "shell.execute_reply": "2026-01-08T07:18:22.455036Z"
    },
    "papermill": {
     "duration": 19.265035,
     "end_time": "2026-01-08T07:18:22.457776",
     "exception": false,
     "start_time": "2026-01-08T07:18:03.192741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2 \n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, StratifiedGroupKFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "from collections import Counter, defaultdict\n",
    "import torch.cuda.amp as amp\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from timm.utils import ModelEmaV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3950c646",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:18:22.467290Z",
     "iopub.status.busy": "2026-01-08T07:18:22.466726Z",
     "iopub.status.idle": "2026-01-08T07:18:22.559127Z",
     "shell.execute_reply": "2026-01-08T07:18:22.558493Z"
    },
    "papermill": {
     "duration": 0.098487,
     "end_time": "2026-01-08T07:18:22.560563",
     "exception": false,
     "start_time": "2026-01-08T07:18:22.462076",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.num_header = 3\n",
    "        self.model_name = \"vit_base_patch14_dinov2\"\n",
    "        \n",
    "        if self.model_name == 'convnext_base' or self.model_name == 'vit_base_patch16_224.augreg2_in21k_ft_in1k':\n",
    "            self.img_size = 224\n",
    "        elif self.model_name == 'convnext_tiny':\n",
    "            self.img_size = 500\n",
    "        elif self.model_name == \"vit_base_patch14_dinov2\":\n",
    "            self.img_size = 518\n",
    "\n",
    "        self.freeze_lr = 1e-3\n",
    "        self.unfreeze_lr = 1e-4\n",
    "\n",
    "        self.head_lr = 1e-3\n",
    "        self.backbone_lr = 1e-4\n",
    "        \n",
    "        self.wd = 1e-2\n",
    "\n",
    "        self.warmup_epochs = 3\n",
    "        self.epochs = 1\n",
    "        \n",
    "        self.loss_weights = {'total_loss' : 0.5, 'gdm_loss': 0.2, 'green_loss':0.1}\n",
    "        self.scoring_weights = [0.5, 0.2, 0.1, 0.1, 0.1]\n",
    "\n",
    "        self.train_path = \"/kaggle/input/csiro-biomass/train.csv\"\n",
    "        self.parent_image_path = \"/kaggle/input/csiro-biomass/\"\n",
    "\n",
    "        self.n_folds = 4\n",
    "        self.random_state = 42\n",
    "\n",
    "        self.batch_size = 8\n",
    "        self.num_workers = 4\n",
    "        self.n_epochs_before_unfreeze = 10\n",
    "        self.n_epochs_after_unfreeze = 20\n",
    "\n",
    "        self.all_targets = ['Dry_Total_g', 'GDM_g', 'Dry_Green_g', 'Dry_Clover_g', 'Dry_Dead_g']\n",
    "\n",
    "        self.accumulation_steps = 4\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "class TabularDataLoader:\n",
    "\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "\n",
    "    def load_and_pivot_data(self):\n",
    "        \n",
    "        df = pd.read_csv(self.config.train_path)\n",
    "        df_pivoted = df.pivot(\n",
    "        index=[\"image_path\", \"Pre_GSHH_NDVI\", \"Height_Ave_cm\", 'Sampling_Date', 'State'],\n",
    "        columns=\"target_name\",\n",
    "        values=\"target\",\n",
    "        ).reset_index()\n",
    "\n",
    "        df_pivoted['image_path'] = self.config.parent_image_path + df_pivoted['image_path']\n",
    "\n",
    "        df_pivoted['Sampling_Date'] = pd.to_datetime(df_pivoted['Sampling_Date'])\n",
    "        day = df_pivoted['Sampling_Date'].dt.dayofyear\n",
    "        df_pivoted['date_encoding'] = np.sin(2 * np.pi * day / 365)\n",
    "        \n",
    "        return df_pivoted\n",
    "    \n",
    "    def create_stratified_folds_w_total(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        print(f\"\\nPreparing {self.config.n_folds}-Fold Cross-Validation...\")\n",
    "        \n",
    "        df = df.copy()\n",
    "        df['fold'] = -1\n",
    "        \n",
    "        # Bin targets (continuous → discrete)\n",
    "        # Determine number of bins using Sturges' formula\n",
    "        num_bins = min(10, int(np.floor(1 + np.log2(len(df)))))\n",
    "        print(f\"Stratifying Dry_Total_g into {num_bins} bins\")\n",
    "        \n",
    "        df['total_bin'] = pd.cut(\n",
    "            df['Dry_Total_g'], \n",
    "            bins=num_bins, \n",
    "            labels=False,\n",
    "            duplicates='drop'  # Remove duplicate edges\n",
    "        )\n",
    "        \n",
    "        # Stratified K-Fold split\n",
    "        skf = StratifiedKFold(\n",
    "            n_splits=self.config.n_folds,\n",
    "            shuffle=True,\n",
    "            random_state=self.config.random_state\n",
    "        )\n",
    "        \n",
    "        for fold_num, (_, valid_idx) in enumerate(skf.split(df, df['total_bin'])):\n",
    "            df.loc[valid_idx, 'fold'] = fold_num\n",
    "        \n",
    "        # Remove binning column (no longer needed)\n",
    "        df = df.drop(columns=['total_bin'])\n",
    "        \n",
    "        print(\"\\nFold distribution:\")\n",
    "        print(df['fold'].value_counts().sort_index())\n",
    "        \n",
    "        return df.drop(columns = ['Pre_GSHH_NDVI', 'Height_Ave_cm', 'date_encoding'])\n",
    "\n",
    "    def create_group_folds_w_date(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        print(f\"\\nPreparing {self.config.n_folds}-Fold Cross-Validation...\")\n",
    "        cols_to_keep = ['Pre_GSHH_NDVI', \n",
    "                        'Height_Ave_cm', 'date_encoding']\n",
    "        df = df.copy()\n",
    "        df['fold'] = -1\n",
    "        \n",
    "        #X_scaled = StandardScaler().fit_transform(df[cols_to_keep].values)\n",
    "\n",
    "        #kmeans = KMeans(n_clusters=15, random_state=42)\n",
    "        #clusters = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "        skf = GroupKFold(n_splits=self.config.n_folds)\n",
    "        \n",
    "        for fold, (_, val_idx) in enumerate(skf.split(df, groups = df['Sampling_Date'])):\n",
    "            df.loc[val_idx, \"fold\"] = fold\n",
    "\n",
    "        print(\"\\nFold distribution:\")\n",
    "        print(df['fold'].value_counts().sort_index())\n",
    "        return df.drop(columns = ['Pre_GSHH_NDVI', 'Height_Ave_cm', 'date_encoding', 'Sampling_Date'])\n",
    "                \n",
    "    def create_stratified_groups_fold(self,df: pd.DataFrame) -> pd.DataFrame:\n",
    "        print(f\"\\nPreparing {self.config.n_folds}-Fold Cross-Validation...\")\n",
    "\n",
    "        df[\"State_code\"] = pd.factorize(df[\"State\"])[0]\n",
    "\n",
    "        n_splits = self.config.n_folds\n",
    "        folds = defaultdict(list)\n",
    "        fold_counts = [Counter() for _ in range(n_splits)]\n",
    "        \n",
    "        # Unique dates\n",
    "        dates = df[\"Sampling_Date\"].unique()\n",
    "        \n",
    "        # Trier les dates par nombre d’échantillons\n",
    "        dates = sorted(dates, key=lambda d: len(df[df[\"Sampling_Date\"]==d]), reverse=True)\n",
    "\n",
    "        for date in dates:\n",
    "            date_states = df[df[\"Sampling_Date\"]==date][\"State_code\"]\n",
    "            \n",
    "            # Choisir le fold avec le moins de cette combinaison\n",
    "            fold_idx = np.argmin([sum([fold_counts[i][s] for s in date_states]) for i in range(n_splits)])\n",
    "            \n",
    "            # Ajouter cette date au fold\n",
    "            folds[fold_idx].append(date)\n",
    "            \n",
    "            # Mettre à jour les compteurs\n",
    "            for s in date_states:\n",
    "                fold_counts[fold_idx][s] += 1\n",
    "        \n",
    "        # Ajouter la colonne fold à df\n",
    "        df[\"fold\"] = -1\n",
    "        for fold_idx, date_list in folds.items():\n",
    "            df.loc[df[\"Sampling_Date\"].isin(date_list), \"fold\"] = fold_idx\n",
    "\n",
    "        print(\"\\nFold distribution:\")\n",
    "        print(df['fold'].value_counts().sort_index())\n",
    "        return df.drop(columns = ['Pre_GSHH_NDVI', 'Height_Ave_cm', 'date_encoding', 'Sampling_Date', 'State_code'])\n",
    "\n",
    "    def create_str_group_w_month_and_state(self,df: pd.DataFrame)-> pd.DataFrame:\n",
    "        df = df.copy()\n",
    "        df['fold'] = -1\n",
    "        \n",
    "        groups = df['Sampling_Date'].dt.month\n",
    "        skgf = StratifiedGroupKFold(n_splits=self.config.n_folds,shuffle=True,random_state=self.config.random_state) \n",
    "\n",
    "        X = df[self.config.all_targets]\n",
    "        y = df['State']\n",
    "\n",
    "        for fold, (_, val_idx) in enumerate(skgf.split(X,y=y, groups = groups)):\n",
    "            df.loc[val_idx, \"fold\"] = fold\n",
    "        \n",
    "        print(\"\\nFold distribution:\")\n",
    "        print(df['fold'].value_counts().sort_index())\n",
    "\n",
    "        return pd.DataFrame(df[['image_path', 'Dry_Total_g', 'GDM_g', 'Dry_Green_g', 'Dry_Clover_g', 'Dry_Dead_g', 'fold']])\n",
    "\n",
    "\n",
    "    def create_str_group_w_month_and_bin(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        print(f\"\\nPreparing Optimal {self.config.n_folds}-Fold Cross-Validation...\")\n",
    "        df = df.copy()\n",
    "        df['fold'] = -1\n",
    "    \n",
    "        groups = df['Sampling_Date'] # Ou df['Sampling_Date'].astype(str)\n",
    "    \n",
    "        num_bins = min(10, int(np.floor(1 + np.log2(len(df)))))\n",
    "        df['total_bin'] = pd.cut(\n",
    "            df['Dry_Total_g'], \n",
    "            bins=num_bins, \n",
    "            labels=False\n",
    "        )\n",
    "    \n",
    "        sgkf = StratifiedGroupKFold(\n",
    "            n_splits=self.config.n_folds, \n",
    "            shuffle=True, \n",
    "            random_state=self.config.random_state\n",
    "        )\n",
    "    \n",
    "        for fold, (_, val_idx) in enumerate(sgkf.split(X=df, y=df['total_bin'], groups=groups)):\n",
    "            df.loc[val_idx, \"fold\"] = fold\n",
    "    \n",
    "        print(\"\\nFold distribution (Images count):\")\n",
    "        print(df['fold'].value_counts().sort_index())\n",
    "        \n",
    "        print(\"\\nMean Biomass per Fold:\")\n",
    "        print(df.groupby('fold')['Dry_Total_g'].mean())\n",
    "    \n",
    "        return df.drop(columns=['total_bin'])\n",
    "\n",
    "\n",
    "    \n",
    "class VisionDataTransformer:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.img_size = Config().img_size\n",
    "        return None\n",
    "\n",
    "    def get_left_right_input(self,img):\n",
    "\n",
    "        if img is None:\n",
    "            raise ValueError(\"img error\")\n",
    "        \n",
    "        h, w = img.shape[:2]\n",
    "        \n",
    "        mid = w // 2\n",
    "        \n",
    "        img_left = img[:, :mid]      \n",
    "        img_right = img[:, mid:]\n",
    "\n",
    "        return img_left, img_right\n",
    "    \n",
    "    def data_augmentation_pipeline(self):\n",
    "        \n",
    "        transform = A.Compose([A.RandomRotate90(p=0.5),\n",
    "        A.HorizontalFlip(p=0.5), \n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomBrightnessContrast(\n",
    "        p=0.5\n",
    "        ),\n",
    "        # A.RandomGamma(\n",
    "        #     gamma_limit=(80, 120),\n",
    "        #     p=0.3\n",
    "        # ),\n",
    "        A.Resize(self.img_size, self.img_size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), \n",
    "        ToTensorV2()])\n",
    "        \n",
    "        return transform\n",
    "\n",
    "    def data_reshape_only_pipeline(self):\n",
    "        transform = A.Compose([A.Resize(self.img_size, self.img_size),A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ToTensorV2()])\n",
    "        \n",
    "        return transform\n",
    "        \n",
    "\n",
    "    def transform(self, img, part):\n",
    "        assert part == \"right\" or part == \"left\"\n",
    "        pipeline = self.data_augmentation_pipeline()\n",
    "        \n",
    "        if part == \"right\":\n",
    "            img_cut = self.get_left_right_input(img)[1]\n",
    "        elif part == 'left':\n",
    "            img_cut = self.get_left_right_input(img)[0]\n",
    "        \n",
    "        transformed = pipeline(image = img_cut)\n",
    "        transformed_image = transformed[\"image\"]\n",
    "\n",
    "        return transformed_image\n",
    "\n",
    "    def reshape(self, img, part):\n",
    "        assert part == \"right\" or part == \"left\"\n",
    "        pipeline = self.data_reshape_only_pipeline()\n",
    "        \n",
    "        if part == \"right\":\n",
    "            img_cut = self.get_left_right_input(img)[1]\n",
    "        elif part == 'left':\n",
    "            img_cut = self.get_left_right_input(img)[0]\n",
    "        \n",
    "        transformed = pipeline(image = img_cut)\n",
    "        transformed_image = transformed[\"image\"]\n",
    "\n",
    "        return transformed_image\n",
    "\n",
    "class BiomassDataset:\n",
    "    \n",
    "    def __init__(self, labels, transform = False):\n",
    "\n",
    "        self.labels = labels\n",
    "        self.vision_transformer = VisionDataTransformer()\n",
    "        self.transform = transform\n",
    "        self.train_targets = ['Dry_Total_g', 'GDM_g', 'Dry_Green_g']\n",
    "        self.all_targets = ['Dry_Total_g', 'GDM_g', 'Dry_Green_g', 'Dry_Clover_g', 'Dry_Dead_g']\n",
    "        self.train_targets = self.labels[self.train_targets].values\n",
    "        self.all_targets = self.labels[self.all_targets].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        img_path = self.labels['image_path'].iloc[idx]\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        train_target = self.train_targets[idx]\n",
    "        all_target = self.all_targets[idx]\n",
    "        \n",
    "\n",
    "        train_target_tensor = torch.tensor(train_target, dtype=torch.float32)\n",
    "        all_target_tensor = torch.tensor(all_target, dtype=torch.float32)\n",
    "        \n",
    "        if self.transform:\n",
    "            transformed_image_right = self.vision_transformer.transform(img, 'right')\n",
    "            transformed_image_left = self.vision_transformer.transform(img, 'left')\n",
    "            \n",
    "            return transformed_image_right, transformed_image_left, train_target_tensor, all_target_tensor\n",
    "\n",
    "        else:\n",
    "            image_right = self.vision_transformer.reshape(img, 'right')\n",
    "            image_left = self.vision_transformer.reshape(img, 'left')\n",
    "            return image_right, image_left, train_target_tensor, all_target_tensor\n",
    "\n",
    "\n",
    "\n",
    "class LocalMambaBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Lightweight Mamba-style block (Gated CNN) from the reference notebook.\n",
    "    Efficiently mixes tokens with linear complexity.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, kernel_size=5, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        # Depthwise conv mixes spatial information locally\n",
    "        self.dwconv = nn.Conv1d(dim, dim, kernel_size=kernel_size, padding=kernel_size // 2, groups=dim)\n",
    "        self.gate = nn.Linear(dim, dim)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (Batch, Tokens, Dim)\n",
    "        shortcut = x\n",
    "        x = self.norm(x)\n",
    "        # Gating mechanism\n",
    "        g = torch.sigmoid(self.gate(x))\n",
    "        x = x * g\n",
    "        # Spatial mixing via 1D Conv (requires transpose)\n",
    "        x = x.transpose(1, 2)  # -> (B, D, N)\n",
    "        x = self.dwconv(x)\n",
    "        x = x.transpose(1, 2)  # -> (B, N, D)\n",
    "        # Projection\n",
    "        x = self.proj(x)\n",
    "        x = self.drop(x)\n",
    "        return shortcut + x\n",
    "\n",
    "\n",
    "\n",
    "class CsiroModel(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.backbone_model = timm.create_model(config.model_name, pretrained=True, num_classes=0, global_pool='')\n",
    "\n",
    "        self.n_features = self.backbone_model.num_features\n",
    "        self.n_combined = self.n_features * 2 \n",
    "\n",
    "    \n",
    "\n",
    "        self.fusion = nn.Sequential(\n",
    "            LocalMambaBlock(self.n_features, kernel_size=5, dropout=0.1),\n",
    "            LocalMambaBlock(self.n_features, kernel_size=5, dropout=0.1)\n",
    "        )\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        self.head_total = self.create_head()\n",
    "        self.head_gdm = self.create_head()\n",
    "        self.head_green = self.create_head()\n",
    "        \n",
    "    def create_head(self):\n",
    "\n",
    "        head = nn.Sequential(nn.Linear(self.n_features, self.n_features//2),\n",
    "                            #nn.LayerNorm(self.n_combined//2),\n",
    "                            nn.GELU(),\n",
    "                            nn.Dropout(0.2),\n",
    "                            nn.Linear(self.n_features//2 , 1),\n",
    "                            nn.Softplus()\n",
    "                )\n",
    "        return head\n",
    "\n",
    "    def forward(self, img_right, img_left):\n",
    "\n",
    "        right_embedd = self.backbone_model(img_right)\n",
    "        left_embedd = self.backbone_model(img_left)\n",
    "\n",
    "        combined_embedd = torch.concat([right_embedd, left_embedd], dim = 1)\n",
    "\n",
    "        x_fused = self.fusion(combined_embedd)\n",
    "        x_pool = self.pool(x_fused.transpose(1, 2)).flatten(1)\n",
    "\n",
    "        out_total = self.head_total(x_pool)\n",
    "        out_gdm = self.head_gdm(x_pool)\n",
    "        out_green = self.head_green(x_pool)\n",
    "        \n",
    "        return out_total, out_gdm, out_green\n",
    "\n",
    "\n",
    "class WeightedBiomassLoss(nn.Module):\n",
    "  \n",
    "    def __init__(self, loss_weights: dict[str, float]):\n",
    "\n",
    "        super().__init__()\n",
    "        self.criterion = nn.SmoothL1Loss(beta=5.0) # A variant of Huber loss: nn.SmoothL1Loss(beta=5.0)\n",
    "        self.weights = loss_weights\n",
    "    \n",
    "    def forward(self, predictions, targets):\n",
    "\n",
    "        pred_total, pred_gdm, pred_green = predictions\n",
    "        \n",
    "        true_total = targets[:, 0:1]  # Maintain [B, 1] shape\n",
    "        true_gdm = targets[:, 1:2]\n",
    "        true_green = targets[:, 2:3]\n",
    "        \n",
    "        loss_total = self.criterion(pred_total, true_total)\n",
    "        loss_gdm = self.criterion(pred_gdm, true_gdm)\n",
    "        loss_green = self.criterion(pred_green, true_green)\n",
    "        \n",
    "        total_loss = (\n",
    "            self.weights['total_loss'] * loss_total +\n",
    "            self.weights['gdm_loss'] * loss_gdm +\n",
    "            self.weights['green_loss'] * loss_green\n",
    "        )\n",
    "        \n",
    "        return total_loss\n",
    "\n",
    "\n",
    "def csiro_scheduler(optimizer, max_epochs):\n",
    "    def lr_lambda(epoch):\n",
    "        config = Config()\n",
    "        e = max(0, epoch)\n",
    "        if e < config.warmup_epochs:\n",
    "            return float(e + 1) / float(max(1, config.warmup_epochs))\n",
    "        progress = (e - config.warmup_epochs) / float(max(1, max_epochs - config.warmup_epochs))\n",
    "        progress = min(1.0,progress)\n",
    "        return 0.5 * (1.0 + math.cos(math.pi * progress))\n",
    "    return optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    \n",
    "    def __init__(self,model,ema_model, optimizer, config, loss, train_loader, valid_loader, device):\n",
    "        self.model = model\n",
    "        self.criterion = loss\n",
    "        self.device = device\n",
    "        \n",
    "        self.train_loader = train_loader\n",
    "        self.valid_loader = valid_loader\n",
    "        self.model.to(device)\n",
    "        self.config = config\n",
    "        \n",
    "        self.optimizer = optimizer\n",
    "        self.scaler = amp.GradScaler()\n",
    "        self.epoch_index = 0\n",
    "\n",
    "        self.model_ema = ema_model\n",
    "        self.model_ema.to(device)\n",
    "\n",
    "    def train_one_epoch(self):\n",
    "        self.model.train()\n",
    "        self.model.module.backbone_model.eval()\n",
    "        total_loss = 0\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        pbar = tqdm(self.train_loader, desc=f\"Train Epoch {self.epoch_index}\", leave=False)\n",
    "        \n",
    "        for i, (img_right, img_left, train_targets, all_targets) in enumerate(pbar):\n",
    "            \n",
    "            img_left = img_left.to(self.device)\n",
    "            img_right = img_right.to(self.device)\n",
    "            train_targets = train_targets.to(self.device)\n",
    "\n",
    "            with amp.autocast(): #gradient accumulation\n",
    "                out_total, out_gdm, out_green = self.model(img_right, img_left)\n",
    "\n",
    "                out_tuple = (out_total, out_gdm, out_green)\n",
    "\n",
    "                loss = self.criterion(out_tuple, train_targets)\n",
    "                loss = loss / self.config.accumulation_steps\n",
    "\n",
    "            \n",
    "            self.scaler.scale(loss).backward()\n",
    "            is_last_batch = (i + 1) == len(self.train_loader)\n",
    "            \n",
    "            if (i + 1) % self.config.accumulation_steps == 0 or is_last_batch:\n",
    "                self.scaler.step(self.optimizer)                \n",
    "                self.scaler.update()                \n",
    "                self.optimizer.zero_grad()\n",
    "                self.model_ema.update(self.model) #EMA\n",
    "\n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "            total_loss += loss.item() * self.config.accumulation_steps\n",
    "\n",
    "        self.epoch_index +=1\n",
    "        return total_loss / len(self.train_loader)\n",
    "\n",
    "\n",
    "    def predict_with_tta(self, model, img_right, img_left):\n",
    "        # images shape: (B, C, H, W)\n",
    "        preds_total = []\n",
    "        preds_gdm = []\n",
    "        preds_green = []\n",
    "        \n",
    "        # 1. Original\n",
    "        out_total, out_gdm, out_green = model(img_right, img_left)\n",
    "        preds_total.append(out_total)\n",
    "        preds_gdm.append(out_gdm)\n",
    "        preds_green.append(out_green)\n",
    "        \n",
    "        \n",
    "        # 2. Horizontal Flip\n",
    "        out_h_total, out_h_gdm, out_h_green = model(torch.flip(img_right, [3]), torch.flip(img_left, [3]))\n",
    "        preds_total.append(out_h_total)\n",
    "        preds_gdm.append(out_h_gdm)\n",
    "        preds_green.append(out_h_green)\n",
    "        \n",
    "        # 3. Vertical Flip\n",
    "        out_v_total, out_v_gdm, out_v_green  = model(torch.flip(img_right, [2]), torch.flip(img_left, [2]))\n",
    "        preds_total.append(out_v_total)\n",
    "        preds_gdm.append(out_v_gdm)\n",
    "        preds_green.append(out_v_green)\n",
    "        \n",
    "        \n",
    "        final_pred_total = torch.stack(preds_total).mean(dim=0)\n",
    "        final_pred_gdm = torch.stack(preds_gdm).mean(dim=0)\n",
    "        final_pred_green = torch.stack(preds_green).mean(dim=0)\n",
    "        \n",
    "        return final_pred_total, final_pred_gdm, final_pred_green\n",
    "\n",
    "\n",
    "    def valid_one_epoch(self, scorer, n_fold, tta = False, ema =False):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "\n",
    "        predictions = {'dry_total_pred' : [], 'gdm_pred': [], 'dry_green_pred': []}\n",
    "        targets = []\n",
    "\n",
    "        pbar = tqdm(self.valid_loader, desc=\"Validating\", leave=False)\n",
    "        \n",
    "        with torch.no_grad(): \n",
    "            for img_right, img_left, train_targets, all_targets in pbar:\n",
    "                \n",
    "                img_left = img_left.to(self.device)\n",
    "                img_right = img_right.to(self.device)\n",
    "                train_targets = train_targets.to(self.device)\n",
    "\n",
    "\n",
    "                if tta:\n",
    "                    out_total, out_gdm, out_green = self.predict_with_tta(self.model,img_right, img_left)\n",
    "                else:\n",
    "                    if ema:\n",
    "                        out_total, out_gdm, out_green = self.model_ema(img_right, img_left)\n",
    "                    else:\n",
    "                        out_total, out_gdm, out_green = self.model(img_right, img_left)\n",
    "    \n",
    "                out_tuple = (out_total, out_gdm, out_green)\n",
    "    \n",
    "                loss = self.criterion(out_tuple, train_targets)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                predictions['dry_total_pred'].append(out_total.cpu().numpy())\n",
    "                predictions['gdm_pred'].append(out_gdm.cpu().numpy())\n",
    "                predictions['dry_green_pred'].append(out_green.cpu().numpy())\n",
    "\n",
    "                targets.append(all_targets.cpu().numpy())\n",
    "\n",
    "\n",
    "        predictions = {\n",
    "            k: np.concatenate(v).flatten() \n",
    "            for k, v in predictions.items()\n",
    "        }\n",
    "        targets = np.concatenate(targets)\n",
    "        \n",
    "        avg_loss = total_loss / len(self.valid_loader)\n",
    "        score = scorer.compute_score(predictions, targets)\n",
    "\n",
    "        return avg_loss, score\n",
    "\n",
    "\n",
    "class CsiroScorer:\n",
    "\n",
    "    def __init__(self, scoring_weights):\n",
    "        self.scoring_weights = scoring_weights\n",
    "\n",
    "    def weighted_r2_score(self,y_true, y_pred, weights):\n",
    "        y_true = np.asarray(y_true).reshape(-1)\n",
    "        y_pred = np.asarray(y_pred).reshape(-1)\n",
    "        weights = np.asarray(weights).reshape(-1)\n",
    "\n",
    "        #print(f'y_true: {y_true[:10]}, y_pred: {y_pred[:10]}, weights: {weights[:10]}')\n",
    "        \n",
    "        # Moyenne pondérée\n",
    "        y_mean = np.sum(weights * y_true) / np.sum(weights)\n",
    "    \n",
    "        ss_res = np.sum(weights * (y_true - y_pred) ** 2)\n",
    "        ss_tot = np.sum(weights * (y_true - y_mean) ** 2)\n",
    "\n",
    "        return 1 - ss_res / ss_tot\n",
    "    \n",
    "    \n",
    "    def compute_score(self, pred_targets:dict, true_targets):\n",
    "        \n",
    "        dry_total_pred = np.array(pred_targets['dry_total_pred'])\n",
    "        gdm_pred = np.array(pred_targets['gdm_pred'])\n",
    "        dry_green_pred = np.array(pred_targets['dry_green_pred'])\n",
    "\n",
    "        dry_clover_pred = np.maximum(0, gdm_pred - dry_green_pred)\n",
    "        dry_dead_pred = np.maximum(0, dry_total_pred - gdm_pred)\n",
    "\n",
    "        \n",
    "        y_preds = np.stack([\n",
    "            dry_total_pred, gdm_pred, dry_green_pred, dry_clover_pred, dry_dead_pred\n",
    "        ], axis=1)\n",
    "        \n",
    "\n",
    "        weights_per_target = np.array([\n",
    "        0.5,  # Dry_Total_g\n",
    "        0.2,  # GDM_g\n",
    "        0.1,  # Dry_Green_g\n",
    "        0.1,  # Dry_Clover_g\n",
    "        0.1,  # Dry_Dead_g\n",
    "        ])\n",
    "        \n",
    "        weights = np.tile(weights_per_target, true_targets.shape[0])\n",
    "        \n",
    "        score =self.weighted_r2_score(\n",
    "            y_true=true_targets.reshape(-1),\n",
    "            y_pred=y_preds.reshape(-1),\n",
    "            weights=weights\n",
    "        )\n",
    "        \n",
    "        return float(score)\n",
    "        \n",
    "\n",
    "class CsiroPipeline:\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.tabular_data_loader = TabularDataLoader(self.config)\n",
    "        self.score = CsiroScorer(self.config.scoring_weights)\n",
    "        self.best_score = 0\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.loss = WeightedBiomassLoss(self.config.loss_weights)\n",
    "\n",
    "        self.all_scores = []\n",
    "\n",
    "\n",
    "    def get_train_valid_from_fold(self, df, n_fold : int):\n",
    "        assert n_fold <= self.config.n_folds\n",
    "\n",
    "        train = df[df['fold'] != n_fold].reset_index(drop = True)\n",
    "        valid = df[df['fold'] == n_fold].reset_index(drop = True)\n",
    "\n",
    "        return BiomassDataset(train, transform = True), BiomassDataset(valid, transform = False)\n",
    "\n",
    "\n",
    "    def unfreeze_stages(self,model, stage_ids):\n",
    "        for i in stage_ids:\n",
    "            for p in model.module.backbone_model.stages[i].parameters():\n",
    "                p.requires_grad = True\n",
    "\n",
    "    def unfreeze_backbone(self, model):\n",
    "        for p in model.module.backbone_model.parameters():\n",
    "            p.requires_grad = True\n",
    "    \n",
    "    def valid_one_fold(self, df, n_fold:int, scorer):\n",
    "        self.best_score = 0\n",
    "        self.model = CsiroModel(self.config)\n",
    "        self.model_ema = ModelEmaV2(self.model, decay=0.90)\n",
    "\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            print(f\"Using {torch.cuda.device_count()} GPUs (DataParallel)\")\n",
    "            self.model = nn.DataParallel(self.model)\n",
    "     \n",
    "        train_dataset, valid_dataset = self.get_train_valid_from_fold(df, n_fold)\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.config.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.config.num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "        valid_loader = DataLoader(\n",
    "            valid_dataset,\n",
    "            batch_size=self.config.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.config.num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "\n",
    "        for param in self.model.module.backbone_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        optimizer = optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, self.model.parameters()),\n",
    "            lr=self.config.head_lr,\n",
    "            weight_decay = self.config.wd\n",
    "        )\n",
    "\n",
    "        # scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        #     optimizer, mode='min', factor=0.2, patience=3\n",
    "        # )\n",
    "\n",
    "        scheduler = csiro_scheduler(optimizer, max_epochs = self.config.n_epochs_before_unfreeze)\n",
    "        \n",
    "        trainer = Trainer(self.model, self.model_ema, optimizer, self.config, self.loss, train_loader, valid_loader, self.device)\n",
    "        print(f'\\n=== Fold {n_fold} | Phase 1: Backbone Frozen ===')\n",
    "        for n in range(self.config.n_epochs_before_unfreeze):\n",
    "            train_loss = trainer.train_one_epoch()\n",
    "            valid_loss, score = trainer.valid_one_epoch(scorer, n_fold, tta = True, ema = True)\n",
    "\n",
    "            scheduler.step()\n",
    "            print(f\"[Epoch {n}] Train Loss: {train_loss:.4f} | Val Loss: {valid_loss:.4f} | Score: {score:.4f}\")\n",
    "            if score > self.best_score:\n",
    "                print(f\"  >>> Score Improved ({self.best_score:.4f} -> {score:.4f}). Saving model.\")\n",
    "                torch.save(self.model_ema.module.state_dict(), f\"best_model_fold_{n_fold}.pth\")\n",
    "                self.best_score = score\n",
    "            \n",
    "\n",
    "\n",
    "        for param in self.model.module.backbone_model.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        #Unfreeze Backbone\n",
    "        self.unfreeze_backbone(self.model)\n",
    "\n",
    "        head_lr = self.config.unfreeze_lr        \n",
    "        backbone_lr = head_lr * 0.1\n",
    "\n",
    "        head_params = list(self.model.module.head_total.parameters()) + list(self.model.module.head_gdm.parameters()) + list(self.model.module.head_green.parameters())\n",
    "        \n",
    "        optimizer = optim.Adam([\n",
    "            {'params': self.model.module.backbone_model.parameters(), 'lr': 5e-6, 'weight_decay': self.config.wd}, \n",
    "            {'params': head_params, 'lr': 5e-5, 'weight_decay': self.config.wd}\n",
    "        ]\n",
    "        )\n",
    "\n",
    "        # scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        #     optimizer, mode='min', factor=0.1, patience=2\n",
    "        # )\n",
    "        \n",
    "        scheduler = csiro_scheduler(optimizer, max_epochs = self.config.n_epochs_after_unfreeze)\n",
    "        trainer = Trainer(self.model, self.model_ema, optimizer, self.config, self.loss, train_loader, valid_loader, self.device)\n",
    "\n",
    "        print(f'\\n=== Fold {n_fold} | Phase 2: Backbone Unfrozen ===')\n",
    "        for n in range(self.config.n_epochs_after_unfreeze):\n",
    "            print(f\"epoch {n + self.config.n_epochs_before_unfreeze}\")\n",
    "\n",
    "            # if n == 10:\n",
    "            #     print('Continuation of training: stage 2-3 Backbone Unfreeze')\n",
    "            #     self.unfreeze_stages(self.model, [2,3])\n",
    "            #     optimizer = optim.Adam(\n",
    "            #         filter(lambda p: p.requires_grad, self.model.parameters()),\n",
    "            #         lr=self.config.unfreeze_lr\n",
    "            #     )\n",
    "            #     scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            #         optimizer, mode='min', factor=0.2, patience=3\n",
    "            #     )\n",
    "            #     trainer = Trainer(self.model, optimizer, self.config, self.loss, train_loader, valid_loader, self.device)\n",
    "            \n",
    "            train_loss = trainer.train_one_epoch()\n",
    "            valid_loss, score = trainer.valid_one_epoch(scorer, n_fold, tta = True, ema = True)\n",
    "            scheduler.step()\n",
    "            print(f\"[Epoch {n}] Train Loss: {train_loss:.4f} | Val Loss: {valid_loss:.4f} | Score: {score:.4f}\")\n",
    "            \n",
    "            if score > self.best_score:\n",
    "                print(f\"  >>> Score Improved ({self.best_score:.4f} -> {score:.4f}). Saving model.\")\n",
    "                torch.save(self.model_ema.module.state_dict(), f\"best_model_fold_{n_fold}.pth\")\n",
    "                self.best_score = score\n",
    "        \n",
    "        return self.best_score\n",
    "        \n",
    "\n",
    "    def run(self):\n",
    "        df = self.tabular_data_loader.load_and_pivot_data()\n",
    "        df = self.tabular_data_loader.create_str_group_w_month_and_state(df)\n",
    "        for fold in range(self.config.n_folds):\n",
    "            print(f\"start training on fold {fold}\")\n",
    "            best_score = self.valid_one_fold(df, fold, self.score)\n",
    "            self.all_scores.append(best_score)   \n",
    "\n",
    "        print(self.all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aef25b6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T07:18:22.566198Z",
     "iopub.status.busy": "2026-01-08T07:18:22.565725Z",
     "iopub.status.idle": "2026-01-08T09:14:34.526577Z",
     "shell.execute_reply": "2026-01-08T09:14:34.525509Z"
    },
    "papermill": {
     "duration": 6971.965264,
     "end_time": "2026-01-08T09:14:34.528024",
     "exception": false,
     "start_time": "2026-01-08T07:18:22.562760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "\n",
      "Fold distribution:\n",
      "fold\n",
      "0    115\n",
      "1     91\n",
      "2     95\n",
      "3     56\n",
      "Name: count, dtype: int64\n",
      "start training on fold 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d25036127548b7b5ac5e7789d795d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPUs (DataParallel)\n",
      "\n",
      "=== Fold 0 | Phase 1: Backbone Frozen ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Train Loss: 28.5639 | Val Loss: 14.1115 | Score: -0.3866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 18.6302 | Val Loss: 16.1110 | Score: -0.3375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Train Loss: 16.4941 | Val Loss: 9.3728 | Score: 0.3593\n",
      "  >>> Score Improved (0.0000 -> 0.3593). Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Train Loss: 14.2719 | Val Loss: 8.0945 | Score: 0.4064\n",
      "  >>> Score Improved (0.3593 -> 0.4064). Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Train Loss: 11.5351 | Val Loss: 8.3723 | Score: 0.4706\n",
      "  >>> Score Improved (0.4064 -> 0.4706). Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Train Loss: 9.4000 | Val Loss: 6.3136 | Score: 0.5827\n",
      "  >>> Score Improved (0.4706 -> 0.5827). Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Train Loss: 8.0185 | Val Loss: 6.3514 | Score: 0.5688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] Train Loss: 7.2732 | Val Loss: 5.6913 | Score: 0.6365\n",
      "  >>> Score Improved (0.5827 -> 0.6365). Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] Train Loss: 6.7942 | Val Loss: 6.2510 | Score: 0.6036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] Train Loss: 6.8581 | Val Loss: 6.1095 | Score: 0.6104\n",
      "\n",
      "=== Fold 0 | Phase 2: Backbone Unfrozen ===\n",
      "epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Train Loss: 6.8585 | Val Loss: 5.6571 | Score: 0.6402\n",
      "  >>> Score Improved (0.6365 -> 0.6402). Saving model.\n",
      "epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 7.4198 | Val Loss: 6.4384 | Score: 0.5825\n",
      "epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Train Loss: 6.6596 | Val Loss: 5.6042 | Score: 0.6503\n",
      "  >>> Score Improved (0.6402 -> 0.6503). Saving model.\n",
      "epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Train Loss: 5.6588 | Val Loss: 5.2478 | Score: 0.6706\n",
      "  >>> Score Improved (0.6503 -> 0.6706). Saving model.\n",
      "epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Train Loss: 4.8574 | Val Loss: 5.5586 | Score: 0.6515\n",
      "epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Train Loss: 4.6690 | Val Loss: 7.2925 | Score: 0.5003\n",
      "epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Train Loss: 5.3934 | Val Loss: 6.0441 | Score: 0.5902\n",
      "epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] Train Loss: 4.2785 | Val Loss: 5.3078 | Score: 0.6767\n",
      "  >>> Score Improved (0.6706 -> 0.6767). Saving model.\n",
      "epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] Train Loss: 3.9111 | Val Loss: 5.4152 | Score: 0.6703\n",
      "epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] Train Loss: 3.7170 | Val Loss: 5.4398 | Score: 0.6556\n",
      "epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] Train Loss: 3.5847 | Val Loss: 5.8355 | Score: 0.6538\n",
      "epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] Train Loss: 3.3380 | Val Loss: 5.4601 | Score: 0.6501\n",
      "epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] Train Loss: 3.3513 | Val Loss: 5.3875 | Score: 0.6622\n",
      "epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] Train Loss: 2.9369 | Val Loss: 5.4749 | Score: 0.6421\n",
      "epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] Train Loss: 3.0279 | Val Loss: 5.5991 | Score: 0.6551\n",
      "epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15] Train Loss: 3.1713 | Val Loss: 5.3487 | Score: 0.6560\n",
      "epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16] Train Loss: 2.7295 | Val Loss: 5.7929 | Score: 0.6508\n",
      "epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17] Train Loss: 2.8084 | Val Loss: 5.7119 | Score: 0.6613\n",
      "epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18] Train Loss: 2.8017 | Val Loss: 5.3498 | Score: 0.6584\n",
      "epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19] Train Loss: 2.8543 | Val Loss: 5.5405 | Score: 0.6605\n",
      "start training on fold 1\n",
      "Using 2 GPUs (DataParallel)\n",
      "\n",
      "=== Fold 1 | Phase 1: Backbone Frozen ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Train Loss: 22.9429 | Val Loss: 23.6860 | Score: -0.4636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 14.8920 | Val Loss: 20.1070 | Score: -0.0213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Train Loss: 12.6349 | Val Loss: 15.3550 | Score: 0.3521\n",
      "  >>> Score Improved (0.0000 -> 0.3521). Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Train Loss: 10.8677 | Val Loss: 16.5309 | Score: 0.1829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Train Loss: 8.7569 | Val Loss: 12.7889 | Score: 0.5103\n",
      "  >>> Score Improved (0.3521 -> 0.5103). Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Train Loss: 7.4299 | Val Loss: 9.4583 | Score: 0.6601\n",
      "  >>> Score Improved (0.5103 -> 0.6601). Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Train Loss: 6.8038 | Val Loss: 9.2746 | Score: 0.6791\n",
      "  >>> Score Improved (0.6601 -> 0.6791). Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] Train Loss: 6.4383 | Val Loss: 9.2848 | Score: 0.6848\n",
      "  >>> Score Improved (0.6791 -> 0.6848). Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] Train Loss: 6.1128 | Val Loss: 8.4859 | Score: 0.7178\n",
      "  >>> Score Improved (0.6848 -> 0.7178). Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] Train Loss: 6.2435 | Val Loss: 8.6283 | Score: 0.7209\n",
      "  >>> Score Improved (0.7178 -> 0.7209). Saving model.\n",
      "\n",
      "=== Fold 1 | Phase 2: Backbone Unfrozen ===\n",
      "epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Train Loss: 6.2091 | Val Loss: 8.2809 | Score: 0.7391\n",
      "  >>> Score Improved (0.7209 -> 0.7391). Saving model.\n",
      "epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 5.5722 | Val Loss: 8.0941 | Score: 0.7478\n",
      "  >>> Score Improved (0.7391 -> 0.7478). Saving model.\n",
      "epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Train Loss: 5.0965 | Val Loss: 9.2751 | Score: 0.7568\n",
      "  >>> Score Improved (0.7478 -> 0.7568). Saving model.\n",
      "epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Train Loss: 5.3945 | Val Loss: 9.6049 | Score: 0.6757\n",
      "epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Train Loss: 5.4978 | Val Loss: 8.1007 | Score: 0.7589\n",
      "  >>> Score Improved (0.7568 -> 0.7589). Saving model.\n",
      "epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Train Loss: 5.0396 | Val Loss: 7.4960 | Score: 0.7775\n",
      "  >>> Score Improved (0.7589 -> 0.7775). Saving model.\n",
      "epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Train Loss: 4.5599 | Val Loss: 7.5644 | Score: 0.8050\n",
      "  >>> Score Improved (0.7775 -> 0.8050). Saving model.\n",
      "epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] Train Loss: 4.4030 | Val Loss: 8.2372 | Score: 0.7842\n",
      "epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] Train Loss: 3.9125 | Val Loss: 7.4754 | Score: 0.8018\n",
      "epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] Train Loss: 3.3745 | Val Loss: 7.2194 | Score: 0.8009\n",
      "epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] Train Loss: 3.1661 | Val Loss: 7.1324 | Score: 0.8166\n",
      "  >>> Score Improved (0.8050 -> 0.8166). Saving model.\n",
      "epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] Train Loss: 2.9666 | Val Loss: 7.4607 | Score: 0.8108\n",
      "epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] Train Loss: 3.0528 | Val Loss: 7.2227 | Score: 0.8044\n",
      "epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] Train Loss: 2.8241 | Val Loss: 7.6027 | Score: 0.8056\n",
      "epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] Train Loss: 2.6378 | Val Loss: 7.4141 | Score: 0.8102\n",
      "epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15] Train Loss: 2.4525 | Val Loss: 7.3553 | Score: 0.8026\n",
      "epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16] Train Loss: 2.4750 | Val Loss: 7.5820 | Score: 0.8054\n",
      "epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17] Train Loss: 2.6145 | Val Loss: 7.4503 | Score: 0.8075\n",
      "epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18] Train Loss: 2.4842 | Val Loss: 7.0377 | Score: 0.8083\n",
      "epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19] Train Loss: 2.3333 | Val Loss: 7.0784 | Score: 0.8084\n",
      "start training on fold 2\n",
      "Using 2 GPUs (DataParallel)\n",
      "\n",
      "=== Fold 2 | Phase 1: Backbone Frozen ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Train Loss: 28.2325 | Val Loss: 11.7587 | Score: -0.0874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 16.4887 | Val Loss: 12.5173 | Score: 0.0940\n",
      "  >>> Score Improved (0.0000 -> 0.0940). Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Train Loss: 13.6021 | Val Loss: 12.9395 | Score: 0.1209\n",
      "  >>> Score Improved (0.0940 -> 0.1209). Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Train Loss: 10.8627 | Val Loss: 8.1126 | Score: 0.4920\n",
      "  >>> Score Improved (0.1209 -> 0.4920). Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Train Loss: 8.1514 | Val Loss: 7.1979 | Score: 0.5668\n",
      "  >>> Score Improved (0.4920 -> 0.5668). Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Train Loss: 7.7725 | Val Loss: 6.7323 | Score: 0.6010\n",
      "  >>> Score Improved (0.5668 -> 0.6010). Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Train Loss: 6.8423 | Val Loss: 5.9882 | Score: 0.6554\n",
      "  >>> Score Improved (0.6010 -> 0.6554). Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] Train Loss: 6.7599 | Val Loss: 6.1088 | Score: 0.6482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] Train Loss: 6.5372 | Val Loss: 7.3810 | Score: 0.5903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] Train Loss: 6.3794 | Val Loss: 6.5977 | Score: 0.6359\n",
      "\n",
      "=== Fold 2 | Phase 2: Backbone Unfrozen ===\n",
      "epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Train Loss: 6.9947 | Val Loss: 8.4270 | Score: 0.5313\n",
      "epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 6.2167 | Val Loss: 5.6730 | Score: 0.6484\n",
      "epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Train Loss: 5.9278 | Val Loss: 6.3565 | Score: 0.6695\n",
      "  >>> Score Improved (0.6554 -> 0.6695). Saving model.\n",
      "epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Train Loss: 4.9630 | Val Loss: 7.0070 | Score: 0.6271\n",
      "epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Train Loss: 4.9901 | Val Loss: 5.2369 | Score: 0.7052\n",
      "  >>> Score Improved (0.6695 -> 0.7052). Saving model.\n",
      "epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Train Loss: 4.5748 | Val Loss: 6.7638 | Score: 0.6381\n",
      "epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Train Loss: 4.1801 | Val Loss: 5.0528 | Score: 0.7145\n",
      "  >>> Score Improved (0.7052 -> 0.7145). Saving model.\n",
      "epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] Train Loss: 4.0963 | Val Loss: 5.3546 | Score: 0.6899\n",
      "epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] Train Loss: 3.7324 | Val Loss: 5.2753 | Score: 0.7245\n",
      "  >>> Score Improved (0.7145 -> 0.7245). Saving model.\n",
      "epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] Train Loss: 3.7814 | Val Loss: 5.3581 | Score: 0.7236\n",
      "epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] Train Loss: 3.4710 | Val Loss: 4.9394 | Score: 0.6981\n",
      "epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] Train Loss: 3.3802 | Val Loss: 5.3486 | Score: 0.7148\n",
      "epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] Train Loss: 3.0141 | Val Loss: 6.2726 | Score: 0.6782\n",
      "epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] Train Loss: 3.0967 | Val Loss: 5.3283 | Score: 0.7219\n",
      "epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] Train Loss: 2.7894 | Val Loss: 4.9534 | Score: 0.7340\n",
      "  >>> Score Improved (0.7245 -> 0.7340). Saving model.\n",
      "epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15] Train Loss: 2.7108 | Val Loss: 5.1457 | Score: 0.7279\n",
      "epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16] Train Loss: 2.6208 | Val Loss: 5.0888 | Score: 0.7290\n",
      "epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17] Train Loss: 2.5248 | Val Loss: 5.0872 | Score: 0.7307\n",
      "epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18] Train Loss: 2.6057 | Val Loss: 5.0461 | Score: 0.7330\n",
      "epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19] Train Loss: 2.5249 | Val Loss: 5.0361 | Score: 0.7320\n",
      "start training on fold 3\n",
      "Using 2 GPUs (DataParallel)\n",
      "\n",
      "=== Fold 3 | Phase 1: Backbone Frozen ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Train Loss: 22.5214 | Val Loss: 25.5136 | Score: -0.4429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 14.7249 | Val Loss: 23.1457 | Score: -0.2781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Train Loss: 12.0282 | Val Loss: 15.9783 | Score: 0.2485\n",
      "  >>> Score Improved (0.0000 -> 0.2485). Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Train Loss: 9.8968 | Val Loss: 13.9597 | Score: 0.3681\n",
      "  >>> Score Improved (0.2485 -> 0.3681). Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Train Loss: 8.1998 | Val Loss: 13.2416 | Score: 0.4123\n",
      "  >>> Score Improved (0.3681 -> 0.4123). Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Train Loss: 7.0456 | Val Loss: 12.7137 | Score: 0.4247\n",
      "  >>> Score Improved (0.4123 -> 0.4247). Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Train Loss: 6.6767 | Val Loss: 11.8411 | Score: 0.4765\n",
      "  >>> Score Improved (0.4247 -> 0.4765). Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] Train Loss: 5.8490 | Val Loss: 11.3773 | Score: 0.5047\n",
      "  >>> Score Improved (0.4765 -> 0.5047). Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] Train Loss: 5.5599 | Val Loss: 11.6047 | Score: 0.4924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] Train Loss: 5.4617 | Val Loss: 11.1916 | Score: 0.5183\n",
      "  >>> Score Improved (0.5047 -> 0.5183). Saving model.\n",
      "\n",
      "=== Fold 3 | Phase 2: Backbone Unfrozen ===\n",
      "epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Train Loss: 5.8367 | Val Loss: 10.9304 | Score: 0.5590\n",
      "  >>> Score Improved (0.5183 -> 0.5590). Saving model.\n",
      "epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 5.5850 | Val Loss: 10.2258 | Score: 0.5816\n",
      "  >>> Score Improved (0.5590 -> 0.5816). Saving model.\n",
      "epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Train Loss: 4.8586 | Val Loss: 10.3822 | Score: 0.5611\n",
      "epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Train Loss: 5.1080 | Val Loss: 9.8259 | Score: 0.6514\n",
      "  >>> Score Improved (0.5816 -> 0.6514). Saving model.\n",
      "epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Train Loss: 4.6596 | Val Loss: 10.8396 | Score: 0.5449\n",
      "epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Train Loss: 4.5165 | Val Loss: 10.0783 | Score: 0.5689\n",
      "epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Train Loss: 3.9046 | Val Loss: 9.1675 | Score: 0.6483\n",
      "epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] Train Loss: 3.2478 | Val Loss: 9.2273 | Score: 0.6216\n",
      "epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] Train Loss: 2.8693 | Val Loss: 9.6539 | Score: 0.6219\n",
      "epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] Train Loss: 2.8405 | Val Loss: 9.1493 | Score: 0.6321\n",
      "epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] Train Loss: 2.7322 | Val Loss: 9.9953 | Score: 0.6430\n",
      "epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] Train Loss: 2.9006 | Val Loss: 9.6560 | Score: 0.6244\n",
      "epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] Train Loss: 2.6871 | Val Loss: 9.5457 | Score: 0.6162\n",
      "epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] Train Loss: 2.5416 | Val Loss: 9.2226 | Score: 0.6336\n",
      "epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] Train Loss: 2.3306 | Val Loss: 9.4558 | Score: 0.6234\n",
      "epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15] Train Loss: 2.1091 | Val Loss: 9.8705 | Score: 0.6306\n",
      "epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16] Train Loss: 2.0506 | Val Loss: 9.8049 | Score: 0.6342\n",
      "epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17] Train Loss: 2.0439 | Val Loss: 9.6142 | Score: 0.6274\n",
      "epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18] Train Loss: 2.0432 | Val Loss: 9.5799 | Score: 0.6260\n",
      "epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19] Train Loss: 2.0501 | Val Loss: 9.6305 | Score: 0.6273\n",
      "[0.6766994394646929, 0.8166043147154585, 0.7340455502715365, 0.6514164163460323]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "print(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "pipeline = CsiroPipeline(config)\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c183c41",
   "metadata": {
    "papermill": {
     "duration": 0.428599,
     "end_time": "2026-01-08T09:14:35.398460",
     "exception": false,
     "start_time": "2026-01-08T09:14:34.969861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14254895,
     "sourceId": 112509,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7000.315595,
   "end_time": "2026-01-08T09:14:39.110033",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-08T07:17:58.794438",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1cf2b3e1866047d1b9c72733eff25b31": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8d46111502cd4712a24e34f6cd44eb06",
       "placeholder": "​",
       "style": "IPY_MODEL_25d795a566ce409d82fd6c68cee33960",
       "tabbable": null,
       "tooltip": null,
       "value": " 346M/346M [00:01&lt;00:00, 337MB/s]"
      }
     },
     "25d795a566ce409d82fd6c68cee33960": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "330689c110e644ad9355ddca290cfe63": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5a7ab325adcf4ee7b7e78326e6245dbf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_330689c110e644ad9355ddca290cfe63",
       "placeholder": "​",
       "style": "IPY_MODEL_ee351191410c4b44b4789fd0f3982207",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "87d83071390f416099c1831470cf130b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8d46111502cd4712a24e34f6cd44eb06": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "97d25036127548b7b5ac5e7789d795d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5a7ab325adcf4ee7b7e78326e6245dbf",
        "IPY_MODEL_e74eecf21e214b6b87637d6568089505",
        "IPY_MODEL_1cf2b3e1866047d1b9c72733eff25b31"
       ],
       "layout": "IPY_MODEL_a239ddada9ce4cd1a59ae4e88b46e3a2",
       "tabbable": null,
       "tooltip": null
      }
     },
     "a239ddada9ce4cd1a59ae4e88b46e3a2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b1f93a93c6e2497d973a98af8fd089a6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e74eecf21e214b6b87637d6568089505": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b1f93a93c6e2497d973a98af8fd089a6",
       "max": 346334872.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_87d83071390f416099c1831470cf130b",
       "tabbable": null,
       "tooltip": null,
       "value": 346334872.0
      }
     },
     "ee351191410c4b44b4789fd0f3982207": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
