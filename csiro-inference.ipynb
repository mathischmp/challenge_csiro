{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70f1c586",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T09:53:02.666213Z",
     "iopub.status.busy": "2026-01-08T09:53:02.665333Z",
     "iopub.status.idle": "2026-01-08T09:53:54.041168Z",
     "shell.execute_reply": "2026-01-08T09:53:54.040335Z"
    },
    "papermill": {
     "duration": 51.380633,
     "end_time": "2026-01-08T09:53:54.042639",
     "exception": false,
     "start_time": "2026-01-08T09:53:02.662006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/albumentations/check_version.py:147: UserWarning: Error fetching version info <urlopen error [Errno -3] Temporary failure in name resolution>\n",
      "  data = fetch_version_info()\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2 \n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbcb035e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T09:53:54.047721Z",
     "iopub.status.busy": "2026-01-08T09:53:54.047486Z",
     "iopub.status.idle": "2026-01-08T09:53:54.070918Z",
     "shell.execute_reply": "2026-01-08T09:53:54.070164Z"
    },
    "papermill": {
     "duration": 0.027498,
     "end_time": "2026-01-08T09:53:54.072169",
     "exception": false,
     "start_time": "2026-01-08T09:53:54.044671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_set_path = \"/kaggle/input/csiro-biomass/test.csv\"\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.num_header = 3\n",
    "        self.model_name = \"vit_base_patch14_dinov2\"\n",
    "        self.img_size = 518\n",
    "\n",
    "        self.lr = 1e-4\n",
    "        self.loss_weights = {'total_loss' : 0.5, 'gdm_loss': 0.2, 'green_loss':0.1}\n",
    "        self.scoring_weights = [0.5, 0.2, 0.1, 0.1, 0.1]\n",
    "\n",
    "        self.train_path = \"/kaggle/input/csiro-biomass/train.csv\"\n",
    "        self.parent_image_path = \"/kaggle/input/csiro-biomass/\"\n",
    "\n",
    "        self.n_folds = 5\n",
    "        self.random_state = 42\n",
    "\n",
    "        self.batch_size = 4\n",
    "        self.num_workers = 2\n",
    "        self.n_epochs = 25\n",
    "\n",
    "\n",
    "class VisionDataTransformer:\n",
    "    def __init__(self):\n",
    "        self.img_size = Config().img_size\n",
    "        return None\n",
    "\n",
    "    def get_left_right_input(self,img):\n",
    "\n",
    "        if img is None:\n",
    "            raise ValueError(\"img error\")\n",
    "        \n",
    "        h, w = img.shape[:2]\n",
    "        \n",
    "        mid = w // 2\n",
    "        \n",
    "        img_left = img[:, :mid]      \n",
    "        img_right = img[:, mid:]\n",
    "\n",
    "        return img_left, img_right\n",
    "    \n",
    "    def data_reshape_only_pipeline(self):\n",
    "        \n",
    "        transform = A.Compose([A.Resize(self.img_size, self.img_size),A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ToTensorV2()])\n",
    "        \n",
    "        return transform\n",
    "        \n",
    "    def reshape(self, img, part):\n",
    "        assert part == \"right\" or part == \"left\"\n",
    "        \n",
    "        pipeline = self.data_reshape_only_pipeline()\n",
    "        \n",
    "        if part == \"right\":\n",
    "            img_cut = self.get_left_right_input(img)[1]\n",
    "        elif part == 'left':\n",
    "            img_cut = self.get_left_right_input(img)[0]\n",
    "        \n",
    "        transformed = pipeline(image = img_cut)\n",
    "        transformed_image = transformed[\"image\"]\n",
    "\n",
    "        return transformed_image\n",
    "\n",
    "class BiomassDataset:\n",
    "    \n",
    "    def __init__(self, labels):\n",
    "\n",
    "        self.labels = labels\n",
    "        self.vision_transformer = VisionDataTransformer()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        img_path = self.labels['image_path'].iloc[idx]\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        image_right = self.vision_transformer.reshape(img, 'right')\n",
    "        image_left = self.vision_transformer.reshape(img, 'left')\n",
    "        \n",
    "        return image_right, image_left\n",
    "\n",
    "# class CsiroModel(nn.Module):\n",
    "\n",
    "#     def __init__(self, config):\n",
    "\n",
    "#         super().__init__()\n",
    "#         self.config = config\n",
    "#         self.backbone_model = timm.create_model(config.model_name, pretrained=False, num_classes=0)\n",
    "\n",
    "#         self.n_features = self.backbone_model.num_features\n",
    "#         self.n_combined = self.n_features * 2 \n",
    "\n",
    "#         self.head_total = self.create_head()\n",
    "#         self.head_gdm = self.create_head()\n",
    "#         self.head_green = self.create_head()\n",
    "        \n",
    "#     def create_head(self):\n",
    "        \n",
    "#         head = nn.Sequential(nn.Linear(self.n_combined, self.n_combined // 2),\n",
    "#                             nn.ReLU(),\n",
    "#                             nn.Dropout(0.3),\n",
    "#                             nn.Linear(self.n_combined // 2 , 1)\n",
    "#                 )\n",
    "#         return head\n",
    "\n",
    "#     def forward(self, img_right, img_left):\n",
    "\n",
    "#         right_embedd = self.backbone_model(img_right)\n",
    "#         left_embedd = self.backbone_model(img_left)\n",
    "\n",
    "#         combined_embedd = torch.concat([right_embedd, left_embedd], dim = 1)\n",
    "\n",
    "#         out_total = self.head_total(combined_embedd)\n",
    "#         out_gdm = self.head_gdm(combined_embedd)\n",
    "#         out_green = self.head_green(combined_embedd)\n",
    "        \n",
    "#         return out_total, out_gdm, out_green\n",
    "\n",
    "\n",
    "class LocalMambaBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Lightweight Mamba-style block (Gated CNN) from the reference notebook.\n",
    "    Efficiently mixes tokens with linear complexity.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, kernel_size=5, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        # Depthwise conv mixes spatial information locally\n",
    "        self.dwconv = nn.Conv1d(dim, dim, kernel_size=kernel_size, padding=kernel_size // 2, groups=dim)\n",
    "        self.gate = nn.Linear(dim, dim)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (Batch, Tokens, Dim)\n",
    "        shortcut = x\n",
    "        x = self.norm(x)\n",
    "        # Gating mechanism\n",
    "        g = torch.sigmoid(self.gate(x))\n",
    "        x = x * g\n",
    "        # Spatial mixing via 1D Conv (requires transpose)\n",
    "        x = x.transpose(1, 2)  # -> (B, D, N)\n",
    "        x = self.dwconv(x)\n",
    "        x = x.transpose(1, 2)  # -> (B, N, D)\n",
    "        # Projection\n",
    "        x = self.proj(x)\n",
    "        x = self.drop(x)\n",
    "        return shortcut + x\n",
    "\n",
    "\n",
    "\n",
    "class CsiroModel(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.backbone_model = timm.create_model(config.model_name, pretrained=False, num_classes=0, global_pool='')\n",
    "\n",
    "        self.n_features = self.backbone_model.num_features\n",
    "        self.n_combined = self.n_features * 2 \n",
    "\n",
    "    \n",
    "\n",
    "        self.fusion = nn.Sequential(\n",
    "            LocalMambaBlock(self.n_features, kernel_size=5, dropout=0.1),\n",
    "            LocalMambaBlock(self.n_features, kernel_size=5, dropout=0.1)\n",
    "        )\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        self.head_total = self.create_head()\n",
    "        self.head_gdm = self.create_head()\n",
    "        self.head_green = self.create_head()\n",
    "        \n",
    "    def create_head(self):\n",
    "\n",
    "        head = nn.Sequential(nn.Linear(self.n_features, self.n_features//2),\n",
    "                            #nn.LayerNorm(self.n_combined//2),\n",
    "                            nn.GELU(),\n",
    "                            nn.Dropout(0.2),\n",
    "                            nn.Linear(self.n_features//2 , 1),\n",
    "                            nn.Softplus()\n",
    "                )\n",
    "        return head\n",
    "\n",
    "    def forward(self, img_right, img_left):\n",
    "\n",
    "        right_embedd = self.backbone_model(img_right)\n",
    "        left_embedd = self.backbone_model(img_left)\n",
    "\n",
    "        combined_embedd = torch.concat([right_embedd, left_embedd], dim = 1)\n",
    "\n",
    "        x_fused = self.fusion(combined_embedd)\n",
    "        x_pool = self.pool(x_fused.transpose(1, 2)).flatten(1)\n",
    "\n",
    "        out_total = self.head_total(x_pool)\n",
    "        out_gdm = self.head_gdm(x_pool)\n",
    "        out_green = self.head_green(x_pool)\n",
    "        \n",
    "        return out_total, out_gdm, out_green\n",
    "\n",
    "\n",
    "\n",
    "def data_preparator(path):\n",
    "    \n",
    "        parent_path = \"/kaggle/input/csiro-biomass/\"\n",
    "        df = pd.read_csv(path)\n",
    "\n",
    "        df_pivoted = df.pivot(index=[\"image_path\"], columns=\"target_name\", values=\"target_name\").reset_index()\n",
    "        df_pivoted['image_path'] = parent_path + df_pivoted['image_path']\n",
    "\n",
    "        test_dataset = BiomassDataset(df_pivoted)\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size= 4,\n",
    "            shuffle=False,\n",
    "            num_workers=1,\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "        return test_loader\n",
    "\n",
    "def load_models():\n",
    "    config = Config()\n",
    "    models = []\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    for i in range(4):\n",
    "        model = CsiroModel(config)\n",
    "        state = torch.load(f\"/kaggle/input/csiro-10/pytorch/default/1/best_model_fold_{i}.pth\", weights_only=True)\n",
    "        model.load_state_dict(state)\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        models.append(model)\n",
    "        \n",
    "    return models\n",
    "\n",
    "def predict_with_tta(model, img_right, img_left):\n",
    "        # images shape: (B, C, H, W)\n",
    "        preds_total = []\n",
    "        preds_gdm = []\n",
    "        preds_green = []\n",
    "        \n",
    "        # 1. Original\n",
    "        out_total, out_gdm, out_green = model(img_right, img_left)\n",
    "        preds_total.append(out_total)\n",
    "        preds_gdm.append(out_gdm)\n",
    "        preds_green.append(out_green)\n",
    "        \n",
    "        \n",
    "        # 2. Horizontal Flip\n",
    "        out_h_total, out_h_gdm, out_h_green = model(torch.flip(img_right, [3]), torch.flip(img_left, [3]))\n",
    "        preds_total.append(out_h_total)\n",
    "        preds_gdm.append(out_h_gdm)\n",
    "        preds_green.append(out_h_green)\n",
    "        \n",
    "        # 3. Vertical Flip\n",
    "        out_v_total, out_v_gdm, out_v_green  = model(torch.flip(img_right, [2]), torch.flip(img_left, [2]))\n",
    "        preds_total.append(out_v_total)\n",
    "        preds_gdm.append(out_v_gdm)\n",
    "        preds_green.append(out_v_green)\n",
    "        \n",
    "        \n",
    "        final_pred_total = torch.stack(preds_total).mean(dim=0)\n",
    "        final_pred_gdm = torch.stack(preds_gdm).mean(dim=0)\n",
    "        final_pred_green = torch.stack(preds_green).mean(dim=0)\n",
    "        \n",
    "        return final_pred_total, final_pred_gdm, final_pred_green\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def infer(tta = False):\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    models = load_models()\n",
    "    test_loader = data_preparator(test_set_path)\n",
    "\n",
    "    \n",
    "    predictions = {'model_1_preds': [],'model_2_preds': [], 'model_3_preds': [], 'model_4_preds': []}\n",
    "    final_predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img_right, img_left in test_loader:\n",
    "            img_left = img_left.to(device)\n",
    "            img_right = img_right.to(device)\n",
    "\n",
    "            model_number = 1\n",
    "            \n",
    "            for model in models:\n",
    "\n",
    "                if tta:\n",
    "                    pred_total, pred_gdm, pred_green = predict_with_tta(model, img_right, img_left)\n",
    "                \n",
    "                else:\n",
    "                \n",
    "                    pred_total, pred_gdm, pred_green = model(img_right, img_left)\n",
    "                \n",
    "                pred_total = np.maximum(0,pred_total.cpu().numpy())\n",
    "                pred_gdm = np.maximum(0,pred_gdm.cpu().numpy())\n",
    "                pred_green = np.maximum( 0, pred_green.cpu().numpy())\n",
    "                \n",
    "                pred_clover = np.maximum(0,pred_gdm - pred_green)\n",
    "                pred_dead = np.maximum(0, pred_total - pred_gdm)\n",
    "\n",
    "                predictions[f'model_{model_number}_preds'].append(np.array([pred_clover, pred_dead, pred_green, pred_total, pred_gdm]).T)\n",
    "\n",
    "                model_number += 1\n",
    "\n",
    "\n",
    "            model_number = 0\n",
    "\n",
    "    \n",
    "    predictions = {\n",
    "            k: np.concatenate(v, axis = 1).flatten() \n",
    "            for k, v in predictions.items()\n",
    "        }\n",
    "    \n",
    "    predictions = pd.DataFrame.from_dict(predictions)\n",
    "\n",
    "    #predictions = predictions['model_1_preds']\n",
    "    \n",
    "    predictions = np.average(predictions, axis=1)\n",
    "\n",
    "    submission = pd.read_csv(test_set_path)\n",
    "    submission['target'] = predictions\n",
    "\n",
    "    submission = submission[['sample_id','target']]\n",
    "\n",
    "    submission.to_csv('submission.csv', index = False)\n",
    "    \n",
    "    return submission\n",
    "\n",
    "                \n",
    "            \n",
    "        \n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fb72952",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T09:53:54.076713Z",
     "iopub.status.busy": "2026-01-08T09:53:54.076203Z",
     "iopub.status.idle": "2026-01-08T09:54:10.265787Z",
     "shell.execute_reply": "2026-01-08T09:54:10.265045Z"
    },
    "papermill": {
     "duration": 16.193306,
     "end_time": "2026-01-08T09:54:10.267141",
     "exception": false,
     "start_time": "2026-01-08T09:53:54.073835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = infer(tta = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9289e11f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T09:54:10.272182Z",
     "iopub.status.busy": "2026-01-08T09:54:10.271520Z",
     "iopub.status.idle": "2026-01-08T09:54:10.277653Z",
     "shell.execute_reply": "2026-01-08T09:54:10.277091Z"
    },
    "papermill": {
     "duration": 0.009695,
     "end_time": "2026-01-08T09:54:10.278671",
     "exception": false,
     "start_time": "2026-01-08T09:54:10.268976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7196914301994299"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([0.6766994394646929, 0.8166043147154585, 0.7340455502715365, 0.6514164163460323])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3502711",
   "metadata": {
    "papermill": {
     "duration": 0.001548,
     "end_time": "2026-01-08T09:54:10.281983",
     "exception": false,
     "start_time": "2026-01-08T09:54:10.280435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14254895,
     "sourceId": 112509,
     "sourceType": "competition"
    },
    {
     "modelId": 534802,
     "modelInstanceId": 520518,
     "sourceId": 686238,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 536128,
     "modelInstanceId": 522023,
     "sourceId": 688525,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 552218,
     "modelInstanceId": 538975,
     "sourceId": 709568,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 555064,
     "modelInstanceId": 541871,
     "sourceId": 713124,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 75.516643,
   "end_time": "2026-01-08T09:54:13.330601",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-08T09:52:57.813958",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
